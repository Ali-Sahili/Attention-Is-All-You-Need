# Attention-Is-All-You-Need
Implmenetation of self-attention, multi-head Attention and Transformer networks and testing on a toy dataset.
